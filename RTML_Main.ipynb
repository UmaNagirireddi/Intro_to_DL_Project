{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMqOYTUWgh5xoVRM2BLuJ+t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indhu68/Intro_to_DL_Project/blob/main/RTML_Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "bPdW9nGmwbbE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv('/content/drive/My Drive/Kasungu_Telemetry_Pts_Oct23.csv', parse_dates=['Time.Stamp'])\n",
        "data = data[[\"Index\",\"Tag\", \"Latitude\", \"Longitude\", \"Time.Stamp\"]]\n",
        "data['Time.Stamp'] = pd.to_datetime(data['Time.Stamp'])\n",
        "data.sort_values(by=['Tag', 'Time.Stamp'], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VBlY-9Mz1pV",
        "outputId": "1dbfe07d-60a4-42c9-9df4-6ba13fa58bb4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate speed and distances\n",
        "epsilon = 1e-5  # Small constant to avoid division by zero\n",
        "data['Time_diff'] = data.groupby('Tag')['Time.Stamp'].diff().dt.total_seconds().fillna(0)\n",
        "data['Lat_diff'] = data.groupby('Tag')['Latitude'].diff().fillna(0)\n",
        "data['Lon_diff'] = data.groupby('Tag')['Longitude'].diff().fillna(0)\n",
        "data['Speed'] = np.sqrt(data['Lat_diff']**2 + data['Lon_diff']**2) / (data['Time_diff'] + epsilon)"
      ],
      "metadata": {
        "id": "Vxl-b3vaz5Y-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle potential infinite or NaN values\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.fillna(data.mean(), inplace=True)  # Fill NaNs with the mean of the column\n"
      ],
      "metadata": {
        "id": "sOwEha8dz7o5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "data[['Latitude', 'Longitude', 'Lat_diff', 'Lon_diff', 'Speed']] = scaler.fit_transform(\n",
        "    data[['Latitude', 'Longitude', 'Lat_diff', 'Lon_diff', 'Speed']]\n",
        ")"
      ],
      "metadata": {
        "id": "G_ny0QUDz9N8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(data, n_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data)):\n",
        "        end_ix = i + n_steps + 1\n",
        "        if end_ix > len(data):\n",
        "            break\n",
        "        seq_x = data.iloc[i:end_ix-1].to_numpy()\n",
        "        seq_y = data.iloc[end_ix-1][['Latitude', 'Longitude']].to_numpy()\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Prepare sequences\n",
        "grouped = data.groupby('Tag')\n",
        "X, y = [], []\n",
        "for _, group in grouped:\n",
        "    sequences = create_sequences(group[['Latitude', 'Longitude', 'Lat_diff', 'Lon_diff', 'Speed']], n_steps=5)\n",
        "    X.append(sequences[0])\n",
        "    y.append(sequences[1])\n",
        "\n",
        "X = np.concatenate(X)\n",
        "y = np.concatenate(y)\n"
      ],
      "metadata": {
        "id": "u_tA8BeAz-vo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "3ejoYiwA0FsY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "8KjHkgkp0Hp_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(5,32)\n",
        "        self.lstm = nn.LSTM(input_size=32, hidden_size=128, num_layers=3, batch_first=True)\n",
        "        self.fc = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "model = LSTMModel().to('cuda')\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "sR5qKiMu0J6x"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            X_batch = X_batch.to('cuda')\n",
        "            y_batch = y_batch.to('cuda')\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}')\n",
        "\n",
        "# Prepare data loaders\n",
        "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=64, shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, criterion, optimizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXgrrBPk0LjT",
        "outputId": "fa4c3304-5520-4a02-e1a6-eead749253a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.000694218862209818\n",
            "Epoch 2, Loss: 2.363142190976811e-05\n",
            "Epoch 3, Loss: 1.8318997013472273e-05\n",
            "Epoch 4, Loss: 1.6594050099878602e-05\n",
            "Epoch 5, Loss: 1.5442011992024492e-05\n",
            "Epoch 6, Loss: 1.4452663257021364e-05\n",
            "Epoch 7, Loss: 1.3492196730636292e-05\n",
            "Epoch 8, Loss: 1.3535400747145868e-05\n",
            "Epoch 9, Loss: 1.2673534802387248e-05\n",
            "Epoch 10, Loss: 1.2237672715460871e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Evaluate Function\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    sample_count = 0  # Initialize the sample counter\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            X_batch = X_batch.to('cuda')\n",
        "            y_batch = y_batch.to('cuda')\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Print actual and predicted values for the first 10 samples\n",
        "            if sample_count < 10:\n",
        "                for actual, predicted in zip(y_batch, predictions):\n",
        "                    print(f'Actual: {actual.cpu().numpy()}, Predicted: {predicted.cpu().numpy()}')\n",
        "                    sample_count += 1\n",
        "                    if sample_count >= 10:\n",
        "                        break\n",
        "\n",
        "    # Print the average loss\n",
        "    print(f'\\nAverage Loss: {total_loss / len(dataloader)}')\n",
        "\n",
        "# Example usage\n",
        "# Assuming 'model', 'test_loader', and 'criterion' are already defined\n",
        "evaluate(model, test_loader, criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64221GfIJ0XY",
        "outputId": "f6ed07d7-1594-4868-e056-d238e637cc44"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual: [0.3329295  0.78440124], Predicted: [0.33421972 0.7847123 ]\n",
            "Actual: [0.4349434  0.89339054], Predicted: [0.43734732 0.89525217]\n",
            "Actual: [0.3239687  0.80752194], Predicted: [0.329485  0.8051759]\n",
            "Actual: [0.29325098 0.77780116], Predicted: [0.29280734 0.7822648 ]\n",
            "Actual: [0.5302073  0.60972446], Predicted: [0.5315625 0.5957586]\n",
            "Actual: [0.3223936 0.6810553], Predicted: [0.32495123 0.6821847 ]\n",
            "Actual: [0.2812679 0.7039108], Predicted: [0.2828736  0.70421046]\n",
            "Actual: [0.6209335  0.71571374], Predicted: [0.6246111 0.7161058]\n",
            "Actual: [0.49855474 0.7646976 ], Predicted: [0.5003591  0.76558983]\n",
            "Actual: [0.18040508 0.59452546], Predicted: [0.17910984 0.5867238 ]\n",
            "\n",
            "Average Loss: 1.0925312754072499e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(5, 32)\n",
        "        self.rnn = nn.RNN(input_size=32, hidden_size=128, num_layers=3, batch_first=True)\n",
        "        self.fc = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        out, _ = self.rnn(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "rnn_model = RNNModel().to('cuda')\n",
        "criterion_rnn = nn.MSELoss()\n",
        "optimizer_rnn = torch.optim.Adam(rnn_model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "jnCXNqXLNfpo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            X_batch = X_batch.to('cuda')\n",
        "            y_batch = y_batch.to('cuda')\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}')\n",
        "\n",
        "# Prepare data loaders\n",
        "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=64, shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, criterion, optimizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIn-XAepNk54",
        "outputId": "1840b9b3-9aa8-4c86-e225-8dafefe3dc7e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.1902292742952133e-05\n",
            "Epoch 2, Loss: 1.1762569800450362e-05\n",
            "Epoch 3, Loss: 1.1426485440491971e-05\n",
            "Epoch 4, Loss: 1.1262521739503699e-05\n",
            "Epoch 5, Loss: 1.1091893240014162e-05\n",
            "Epoch 6, Loss: 1.1086855351411204e-05\n",
            "Epoch 7, Loss: 1.1021604616677645e-05\n",
            "Epoch 8, Loss: 1.0775050233610734e-05\n",
            "Epoch 9, Loss: 1.0727119036216882e-05\n",
            "Epoch 10, Loss: 1.069307076484041e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Evaluate Function\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    sample_count = 0  # Initialize the sample counter\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            X_batch = X_batch.to('cuda')\n",
        "            y_batch = y_batch.to('cuda')\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Print actual and predicted values for the first 10 samples\n",
        "            if sample_count < 10:\n",
        "                for actual, predicted in zip(y_batch, predictions):\n",
        "                    print(f'Actual: {actual.cpu().numpy()}, Predicted: {predicted.cpu().numpy()}')\n",
        "                    sample_count += 1\n",
        "                    if sample_count >= 10:\n",
        "                        break\n",
        "\n",
        "    # Print the average loss\n",
        "    print(f'\\nAverage Loss: {total_loss / len(dataloader)}')\n",
        "\n",
        "# Example usage\n",
        "# Assuming 'model', 'test_loader', and 'criterion' are already defined\n",
        "evaluate(model, test_loader, criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-KKNkpeNqeq",
        "outputId": "52dd1777-a6f5-445e-ca5d-055dbfbfb1e8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual: [0.46375427 0.78844017], Predicted: [0.46440214 0.79019743]\n",
            "Actual: [0.4819719 0.8002212], Predicted: [0.48341405 0.79956317]\n",
            "Actual: [0.46771684 0.6616714 ], Predicted: [0.4713208 0.6655133]\n",
            "Actual: [0.4699237 0.7037069], Predicted: [0.47256953 0.703285  ]\n",
            "Actual: [0.41720405 0.8026573 ], Predicted: [0.417163   0.80552536]\n",
            "Actual: [0.5008492 0.6637181], Predicted: [0.5032791  0.65886444]\n",
            "Actual: [0.438075 0.849946], Predicted: [0.4396276 0.847418 ]\n",
            "Actual: [0.2813803 0.7111361], Predicted: [0.28179872 0.71358055]\n",
            "Actual: [0.49512002 0.7366627 ], Predicted: [0.4960655 0.7364174]\n",
            "Actual: [0.47034848 0.69747025], Predicted: [0.47208422 0.6985734 ]\n",
            "\n",
            "Average Loss: 1.0264667840022784e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(5, 32)\n",
        "        self.gru = nn.GRU(input_size=32, hidden_size=128, num_layers=3, batch_first=True)\n",
        "        self.fc = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        out, _ = self.gru(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "gru_model = GRUModel().to('cuda')\n",
        "criterion_gru = nn.MSELoss()\n",
        "optimizer_gru = torch.optim.Adam(gru_model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "7GWdjsJuNzf9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            X_batch = X_batch.to('cuda')\n",
        "            y_batch = y_batch.to('cuda')\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}')\n",
        "\n",
        "# Prepare data loaders\n",
        "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=64, shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, criterion, optimizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yewRT4VqN14S",
        "outputId": "252e74e3-aaec-4134-ad4c-5b54dd7c5093"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.0439942129530562e-05\n",
            "Epoch 2, Loss: 1.045315089497516e-05\n",
            "Epoch 3, Loss: 1.0412983895918973e-05\n",
            "Epoch 4, Loss: 1.0241018224906148e-05\n",
            "Epoch 5, Loss: 1.0253787625705345e-05\n",
            "Epoch 6, Loss: 1.0228292008670922e-05\n",
            "Epoch 7, Loss: 1.0257761380903183e-05\n",
            "Epoch 8, Loss: 1.0175824001341843e-05\n",
            "Epoch 9, Loss: 1.0023025816745823e-05\n",
            "Epoch 10, Loss: 1.0077576707204017e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Evaluate Function\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    sample_count = 0  # Initialize the sample counter\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            X_batch = X_batch.to('cuda')\n",
        "            y_batch = y_batch.to('cuda')\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Print actual and predicted values for the first 10 samples\n",
        "            if sample_count < 10:\n",
        "                for actual, predicted in zip(y_batch, predictions):\n",
        "                    print(f'Actual: {actual.cpu().numpy()}, Predicted: {predicted.cpu().numpy()}')\n",
        "                    sample_count += 1\n",
        "                    if sample_count >= 10:\n",
        "                        break\n",
        "\n",
        "    # Print the average loss\n",
        "    print(f'\\nAverage Loss: {total_loss / len(dataloader)}')\n",
        "\n",
        "# Example usage\n",
        "# Assuming 'model', 'test_loader', and 'criterion' are already defined\n",
        "evaluate(model, test_loader, criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDOjx7pnN4WU",
        "outputId": "3bbd4d0f-f4d1-4de3-ca04-c725303ce848"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual: [0.15817913 0.697936  ], Predicted: [0.155433 0.697458]\n",
            "Actual: [0.29913282 0.69248897], Predicted: [0.3069551 0.6962958]\n",
            "Actual: [0.22392523 0.6634714 ], Predicted: [0.21982333 0.6626216 ]\n",
            "Actual: [0.44104153 0.75101244], Predicted: [0.44033432 0.7528136 ]\n",
            "Actual: [0.49082646 0.6932996 ], Predicted: [0.49107802 0.69492984]\n",
            "Actual: [0.49132952 0.72646767], Predicted: [0.4931522  0.73474765]\n",
            "Actual: [0.5677836  0.69172364], Predicted: [0.5687713 0.693594 ]\n",
            "Actual: [0.5219364 0.672719 ], Predicted: [0.51989067 0.6723095 ]\n",
            "Actual: [0.18923949 0.6882931 ], Predicted: [0.18551998 0.68697935]\n",
            "Actual: [0.24689299 0.7935146 ], Predicted: [0.24403493 0.7933068 ]\n",
            "\n",
            "Average Loss: 1.0187548256263404e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, num_heads, num_layers, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
        "        transformer_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_dim, nhead=num_heads, dim_feedforward=hidden_dim * 4, batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(transformer_layer, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer(x)\n",
        "        return self.fc_out(x[:, -1, :])\n",
        "\n",
        "# Example initialization and setting up optimizer and loss\n",
        "transformer_attention_model = TransformerModel(input_dim=5, num_heads=4, num_layers=3, hidden_dim=128, output_dim=2).to('cuda')\n",
        "criterion_transformer = nn.MSELoss()\n",
        "optimizer_transformer = torch.optim.Adam(transformer_attention_model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "dKsV1GycO4jO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            X_batch = X_batch.to('cuda')\n",
        "            y_batch = y_batch.to('cuda')\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}')\n",
        "\n",
        "# Prepare data loaders\n",
        "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=64, shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, criterion, optimizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjF6YZE1O_00",
        "outputId": "2ad734af-6ec9-4601-ea6e-e5a37c7f31df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 9.983622884863069e-06\n",
            "Epoch 2, Loss: 9.967951133668944e-06\n",
            "Epoch 3, Loss: 9.857809624612748e-06\n",
            "Epoch 4, Loss: 9.93672460294843e-06\n",
            "Epoch 5, Loss: 9.879981025545194e-06\n",
            "Epoch 6, Loss: 9.834637814751983e-06\n",
            "Epoch 7, Loss: 9.828848025058417e-06\n",
            "Epoch 8, Loss: 9.8025992440049e-06\n",
            "Epoch 9, Loss: 9.748260624470798e-06\n",
            "Epoch 10, Loss: 9.704611033311836e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Evaluate Function\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    sample_count = 0  # Initialize the sample counter\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            X_batch = X_batch.to('cuda')\n",
        "            y_batch = y_batch.to('cuda')\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Print actual and predicted values for the first 10 samples\n",
        "            if sample_count < 10:\n",
        "                for actual, predicted in zip(y_batch, predictions):\n",
        "                    print(f'Actual: {actual.cpu().numpy()}, Predicted: {predicted.cpu().numpy()}')\n",
        "                    sample_count += 1\n",
        "                    if sample_count >= 10:\n",
        "                        break\n",
        "\n",
        "    # Print the average loss\n",
        "    print(f'\\nAverage Loss: {total_loss / len(dataloader)}')\n",
        "\n",
        "# Example usage\n",
        "# Assuming 'model', 'test_loader', and 'criterion' are already defined\n",
        "evaluate(model, test_loader, criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2J1XXrJPIz-",
        "outputId": "32124ba0-4896-4143-b46f-c490e0e269c4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual: [0.2888675 0.6440044], Predicted: [0.2927965 0.6404763]\n",
            "Actual: [0.29327887 0.77694523], Predicted: [0.29583174 0.7765198 ]\n",
            "Actual: [0.5390014 0.6138322], Predicted: [0.5423672 0.6152275]\n",
            "Actual: [0.50507146 0.77018404], Predicted: [0.50661623 0.77154136]\n",
            "Actual: [0.2599357 0.7014261], Predicted: [0.26037076 0.69787014]\n",
            "Actual: [0.487284   0.75936216], Predicted: [0.4874707  0.75906146]\n",
            "Actual: [0.49353948 0.7035727 ], Predicted: [0.495461   0.70303714]\n",
            "Actual: [0.45249674 0.7430093 ], Predicted: [0.4557468 0.7455766]\n",
            "Actual: [0.316535   0.65665066], Predicted: [0.3192597 0.6540148]\n",
            "Actual: [0.3580421  0.85762525], Predicted: [0.3485177  0.85662746]\n",
            "\n",
            "Average Loss: 1.027743973545413e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "below code - don't use"
      ],
      "metadata": {
        "id": "YKzsW_6BPO0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Function\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            X_batch = X_batch.to('cuda')\n",
        "            y_batch = y_batch.to('cuda')\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            total_loss += loss.item()\n",
        "    print(f'Average Loss: {total_loss / len(dataloader)}')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "evaluate(model, test_loader, criterion)"
      ],
      "metadata": {
        "id": "4xR3axfT0TgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction Function\n",
        "def predict_next_position(model, data, tag, timestamp, scaler, n_steps=5):\n",
        "    model.eval()\n",
        "    tag_data = data[data['Tag'] == tag].sort_values(by='Time.Stamp')\n",
        "\n",
        "    idx = tag_data[tag_data['Time.Stamp'] <= timestamp].tail(n_steps).index\n",
        "    if len(idx) < n_steps:\n",
        "        return \"Not enough data points to create a sequence.\"\n",
        "\n",
        "    seq = tag_data.loc[idx, ['Latitude', 'Longitude', 'Lat_diff', 'Lon_diff', 'Speed']]\n",
        "    seq_normalized = scaler.transform(seq)\n",
        "    seq_tensor = torch.tensor(seq_normalized[np.newaxis, :], dtype=torch.float32).to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predicted_position_normalized = model(seq_tensor)\n",
        "        predicted_position_normalized = predicted_position_normalized.cpu().numpy()\n",
        "\n",
        "    # Reshape the prediction to match the scaler's expected input\n",
        "    predicted_position_normalized = np.insert(predicted_position_normalized, 2, [[0, 0, 0]], axis=1)\n",
        "\n",
        "    # Inverse transform to get the actual latitude and longitude\n",
        "    predicted_position = scaler.inverse_transform(predicted_position_normalized)[0, :2]\n",
        "\n",
        "    return predicted_position"
      ],
      "metadata": {
        "id": "JfuB7RWP0YVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_position(model, data, tag, timestamp, scaler, n_steps=5):\n",
        "    model.eval()\n",
        "\n",
        "    # Filter data for the specified tag\n",
        "    tag_data = data[data['Tag'] == tag]\n",
        "\n",
        "    # If the tag does not exist or not enough data points\n",
        "    if tag_data.empty or tag_data[tag_data['Time.Stamp'] < timestamp].shape[0] < n_steps:\n",
        "        return \"Not enough data points to create a sequence.\", None\n",
        "\n",
        "    # Ensure the data is sorted by timestamp\n",
        "    tag_data = tag_data.sort_values(by='Time.Stamp')\n",
        "\n",
        "    # Get the last n_steps records before the given timestamp for the sequence\n",
        "    sequence_data = tag_data[tag_data['Time.Stamp'] < timestamp][-n_steps:]\n",
        "\n",
        "    # Process the sequence for prediction\n",
        "    seq_scaled = scaler.transform(sequence_data[['Latitude', 'Longitude', 'Lat_diff', 'Lon_diff', 'Speed']])\n",
        "    seq_tensor = torch.tensor(seq_scaled[np.newaxis, :], dtype=torch.float32).to('cuda')\n",
        "\n",
        "    # Predict the next position\n",
        "    with torch.no_grad():\n",
        "        predicted_position_scaled = model(seq_tensor)\n",
        "        predicted_position_scaled = predicted_position_scaled.cpu().numpy()\n",
        "\n",
        "    # Reshape for inverse scaling\n",
        "    dummy_data = np.zeros((1, 5))  # Assuming you have 5 features as before\n",
        "    dummy_data[:, :2] = predicted_position_scaled[0, :2]\n",
        "\n",
        "    # Inverse transform to get the actual latitude and longitude\n",
        "    predicted_position = scaler.inverse_transform(dummy_data)[0, :2]\n",
        "\n",
        "    return predicted_position,actual ,True\n",
        "\n",
        "# Example usage\n",
        "timestamp = pd.to_datetime('2022-07-14 11:08:00')  # Ensure this is within the date range of your data\n",
        "tag = 5748  # Use an actual numerical Tag from your dataset\n",
        "predicted_pos, actual, success = predict_next_position(model, data, tag, timestamp, scaler)\n",
        "\n",
        "if not success:\n",
        "    print(predicted_pos)\n",
        "else:\n",
        "    predicted_lat, predicted_lon = predicted_pos\n",
        "    actual_lat, actual_lon = actual\n",
        "    print(f'Predicted Position: Latitude {predicted_lat:.6f}, Longitude {predicted_lon:.6f}')\n",
        "    print(f'Actual Position: Latitude {actual_lat:.6f}, Longitude {actual_lon:.6f}')\n"
      ],
      "metadata": {
        "id": "fXnO8Bye0bWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J6vgcUma2oZN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}